from __future__ import annotations
from typing import List
from collections import Counter
import re
import copy
from .extract import Lawsuit
from .courtlistener import CLDocument, CLCaseSummary
from .utils import debug_log, slugify_case_name

def _esc(s: str) -> str:
    s = str(s or "").strip()
    s = s.replace("\r\n", "\n").replace("\r", "\n")
    s = s.replace("```", "&#96;&#96;&#96;")
    s = s.replace("~~~", "&#126;&#126;&#126;")
    s = s.replace("|", "\\|")
    s = s.replace("\n", "<br>")
    return s


def _md_sep(col_count: int) -> str:
    return "|" + "---|" * col_count


def _mdlink(label: str, url: str) -> str:
    label = _esc(label)
    url = (url or "").strip()
    if not url:
        return label

    # ì´ë¯¸ Markdown ë§í¬ í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì´ì¤‘ ë°©ì§€)
    if url.startswith("[") and "](" in url:
        return url
        
    return f"[{label}]({url})"


def _short(val: str, limit: int = 140) -> str:
    val = val or ""
    if len(val) <= limit:
        return _esc(val)
    return f"<details><summary>ë‚´ìš© í¼ì¹˜ê¸°</summary>{_esc(val)}</details>"


# =====================================================
# slug ë³€í™˜
# =====================================================
def _slugify_case_name(name: str) -> str:
    return slugify_case_name(name)


# =====================================================
# ë‰´ìŠ¤ ìœ„í—˜ë„
# =====================================================
def calculate_news_risk_score(title: str, reason: str) -> int:
    score = 0
    text = f"{title or ''} {reason or ''}".lower()

    # 1. ë¬´ë‹¨ ë°ì´í„° ìˆ˜ì§‘ ëª…ì‹œ (+30)
    if any(k in text for k in ["scrape", "crawl", "ingest", "harvest", "mining", "extraction", "bulk", "collection", "robots.txt", "common crawl", "laion", "the pile", "bookcorpus", "unauthorized"]):
        score += 30
    
    # 2. ëª¨ë¸ í•™ìŠµ ì§ì ‘ ì–¸ê¸‰ (+30)
    if any(k in text for k in ["train", "training", "model", "llm", "generative ai", "genai", "gpt", "transformer", "weight", "fine-tune", "diffusion", "inference"]):
        score += 30
    
    # 3. ìƒì—…ì  ì‚¬ìš© (+15)
    if any(k in text for k in ["commercial", "profit", "monetiz", "revenue", "subscription", "enterprise", "paid", "for-profit"]):
        score += 15
    
    # 4. ì €ì‘ê¶Œ ê´€ë ¨ (ë‰´ìŠ¤ì—ì„œëŠ” Nature of Suit 820 ëŒ€ìš©ìœ¼ë¡œ í‚¤ì›Œë“œ ì²´í¬) (+15)
    if any(k in text for k in ["copyright", "infringement", "dmca", "fair use", "derivative", "exclusive", "820"]):
        score += 15
        
    # 5. ì§‘ë‹¨ì†Œì†¡ (+10)
    if any(k in text for k in ["class action", "putative class", "representative"]):
        score += 10

    return min(score, 100)


def format_risk(score: int) -> str:
    if score >= 80:
        return f"ğŸ”¥ {score}"
    if score >= 60:
        return f"âš ï¸ {score}"
    if score >= 40:
        return f"ğŸŸ¡ {score}"
    return f"ğŸŸ¢ {score}"


# =====================================================
# RECAP ìœ„í—˜ë„
# =====================================================
def calculate_case_risk_score(case: CLCaseSummary) -> int:
    score = 0
    text = f"{case.extracted_ai_snippet or ''} {case.extracted_causes or ''}".lower()

    # 1. ë¬´ë‹¨ ë°ì´í„° ìˆ˜ì§‘ ëª…ì‹œ (+30)
    if any(k in text for k in ["scrape", "crawl", "ingest", "harvest", "mining", "extraction", "bulk", "collection", "robots.txt", "common crawl", "laion", "the pile", "bookcorpus", "unauthorized"]):
        score += 30
    
    # 2. ëª¨ë¸ í•™ìŠµ ì§ì ‘ ì–¸ê¸‰ (+30)
    if any(k in text for k in ["train", "training", "model", "llm", "generative ai", "genai", "gpt", "transformer", "weight", "fine-tune", "diffusion", "inference"]):
        score += 30
    
    # 3. ìƒì—…ì  ì‚¬ìš© (+15)
    if any(k in text for k in ["commercial", "profit", "monetiz", "revenue", "subscription", "enterprise", "paid", "for-profit"]):
        score += 15
    
    # 4. ì €ì‘ê¶Œ ì†Œì†¡ (Nature = 820) (+15)
    # RECAPì˜ ê²½ìš° Nature of Suit ì½”ë“œë¥¼ ìš°ì„ í•˜ë©°, í…ìŠ¤íŠ¸ì—ì„œë„ ì €ì‘ê¶Œ ì¹¨í•´ ìŸì ì„ í™•ì¸í•©ë‹ˆë‹¤.
    if (case.nature_of_suit and "820" in case.nature_of_suit) or any(k in text for k in ["copyright", "infringement", "dmca", "fair use", "derivative", "exclusive"]):
        score += 15
        
    # 5. ì§‘ë‹¨ì†Œì†¡ (+10)
    if any(k in text for k in ["class action", "putative class", "representative"]):
        score += 10

    return min(score, 100)


# =====================================================
# ë©”ì¸ ë Œë”
# =====================================================
def render_markdown(
    lawsuits: List[Lawsuit],
    cl_docs: List[CLDocument],
    cl_cases: List[CLCaseSummary],
    recap_doc_count: int,
    lookback_days: int = 3,
) -> str:

    lines: List[str] = []

    # KPI (ê°„ê²° í…ìŠ¤íŠ¸ ìš”ì•½)
    lines.append(f"## ğŸ“Š ìµœê·¼ {lookback_days}ì¼ ìš”ì•½")
    lines.append(f"â”” ğŸ“° News: {len(lawsuits)}")
    lines.append(f"â”” âš– Cases: {len(cl_cases)} (Docs: {recap_doc_count})\n")

    # Nature í†µê³„
    if cl_cases:
        counter = Counter([c.nature_of_suit or "ë¯¸í™•ì¸" for c in cl_cases])
        lines.append("## ğŸ“Š Nature of Suit í†µê³„\n")
        lines.append("| Nature of Suit | ê±´ìˆ˜ |")
        lines.append("|---|---|")
        for k, v in counter.most_common(10):
            lines.append(f"| {_esc(k)} | **{v}** |")
        # ì´ ê°œìˆ˜ ì¶”ê°€
        total_count = sum(counter.values())
        lines.append(f"| **ì´ê°œìˆ˜** | **{total_count}** |")            
        lines.append("")

    # AI ì†Œì†¡ Top3 (ì—…ë°ì´íŠ¸ ë‚ ì§œ ê¸°ì¤€)
    if cl_cases:
        debug_log("'ìµœê·¼ ì†Œì†¡ Top 3 (ì—…ë°ì´íŠ¸ ë‚ ì§œ ê¸°ì¤€)' is printed.")        
        lines.append("## ğŸ§  ìµœê·¼ ì†Œì†¡ Top 3 (ì—…ë°ì´íŠ¸ ë‚ ì§œ ê¸°ì¤€)\n")
        
        top_cases = sorted(
            cl_cases,
            key=lambda x: x.recent_updates if x.recent_updates != "ë¯¸í™•ì¸" else "",
            reverse=True
        )[:3]

        for idx, c in enumerate(top_cases, start=1):
            update_date = c.recent_updates if c.recent_updates != "ë¯¸í™•ì¸" else ""
            lines.append(f"**({idx}) {_esc(update_date or 'ë¯¸í™•ì¸')}, {_esc(c.case_name)}**")
            
            # Nature
            nature_val = _esc(c.nature_of_suit)
            if nature_val == "820 Copyright":
                nature_val = "âš ï¸**820 Copyright**"
            
            lines.append(f"   - **Nature**: {nature_val}")
            lines.append(f"   - **ì†Œì†¡ì´ìœ **: {_esc(c.extracted_causes or c.cause or 'ë¯¸í™•ì¸')}")
            
            # AIí•™ìŠµê´€ë ¨ í•µì‹¬ì£¼ì¥ (Snippet)
            if c.extracted_ai_snippet:
                lines.append(f"   - **AIí•™ìŠµê´€ë ¨ í•µì‹¬ì£¼ì¥**: {_short(c.extracted_ai_snippet, 200)}")
            else:
                lines.append(f"   - **AIí•™ìŠµê´€ë ¨ í•µì‹¬ì£¼ì¥**: ë¯¸í™•ì¸")
            lines.append("")

    # ë‰´ìŠ¤ í…Œì´ë¸”
    lines.append("## ğŸ“° News")
    if lawsuits:
        debug_log("'News' is printed.")            
        lines.append("| No. | ê¸°ì‚¬ì¼ìâ¬‡ï¸ | ì œëª© | ì†Œì†¡ë²ˆí˜¸ | ì†Œì†¡ì‚¬ìœ  | ìœ„í—˜ë„ ì˜ˆì¸¡ ì ìˆ˜ |")
        lines.append(_md_sep(6))

        # ê¸°ì‚¬ì¼ì ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœ, ë™ì¼ ë‚ ì§œ ì‹œ ìœ„í—˜ë„ ë‚´ë¦¼ì°¨ìˆœ)
        scored_lawsuits = []
        for s in lawsuits:
            risk_score = calculate_news_risk_score(s.article_title or s.case_title, s.reason)
            scored_lawsuits.append((risk_score, s))
        
        scored_lawsuits.sort(key=lambda x: (x[1].update_or_filed_date or "", x[0]), reverse=True)

        for idx, (risk_score, s) in enumerate(scored_lawsuits, start=1):
            article_url = s.article_urls[0] if getattr(s, "article_urls", None) else ""
            title_cell = _mdlink(s.article_title or s.case_title, article_url)

            lines.append(
                f"| {idx} | "
                f"{_esc(s.update_or_filed_date)} | "
                f"{title_cell} | "
                f"{_esc(s.case_number)} | "
                f"{_short(s.reason)} | "
                f"{format_risk(risk_score)} |"
            )
        lines.append("")
    else:
        lines.append("ìƒˆë¡œìš´ ì†Œì‹ì´ 0ê±´ì…ë‹ˆë‹¤.\n")

    # RECAP ì¼€ì´ìŠ¤
    lines.append("## âš–ï¸ Cases (Courtlistener+RECAP)")
    if cl_cases:
        
        # CLDocumentë¥¼ docket_id ê¸°ì¤€ìœ¼ë¡œ ë§¤í•‘
        doc_map = {}
        for d in cl_docs:
            if d.docket_id:
                doc_map[d.docket_id] = d
        
        lines.append(
            "| No. | ìƒíƒœ | ì¼€ì´ìŠ¤ëª… | ë„ì¼“ë²ˆí˜¸ | Nature | ìœ„í—˜ë„ | "
            "ì†Œì†¡ì´ìœ  | AIí•™ìŠµê´€ë ¨ í•µì‹¬ì£¼ì¥ | ë²•ì  ê·¼ê±° | ë‹´ë‹¹íŒì‚¬ | ë²•ì› | "
            "Complaint ë¬¸ì„œ ë²ˆí˜¸ | Complaint PDF ë§í¬ | ìµœê·¼ ë„ì¼“ ì—…ë°ì´íŠ¸â¬‡ï¸ |"
        )
        lines.append(_md_sep(14))
        
        # ìœ„í—˜ë„ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìœ„í—˜ë„ ë‚´ë¦¼ì°¨ìˆœ, ë™ì¼ ì ìˆ˜ ì‹œ ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœ)
        scored_cases = []
        for c in cl_cases:
            # ìµœì¢… ìŠ¤ì½”ì–´ë§ ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ê²°ì •
            ext_causes = c.extracted_causes
            ext_snippet = c.extracted_ai_snippet
            if c.docket_id in doc_map:
                doc = doc_map[c.docket_id]
                ext_causes = doc.extracted_causes or ext_causes
                ext_snippet = doc.extracted_ai_snippet or ext_snippet
            
            # ìœ„í—˜ë„ ê³„ì‚°ìš© ì„ì‹œ ê°ì²´ (ì›ë³¸ ë³´í˜¸)
            c_copy = copy.copy(c)
            c_copy.extracted_ai_snippet = ext_snippet
            c_copy.extracted_causes = ext_causes
            score = calculate_case_risk_score(c_copy)
            scored_cases.append((score, c, ext_causes, ext_snippet))
            
        scored_cases.sort(key=lambda x: (x[0], x[1].recent_updates if x[1].recent_updates != "ë¯¸í™•ì¸" else ""), reverse=True)

        for idx, (score, c, extracted_causes, extracted_ai_snippet) in enumerate(scored_cases, start=1):             
                slug = _slugify_case_name(c.case_name)
                docket_url = f"https://www.courtlistener.com/docket/{c.docket_id}/{slug}/"
      
                complaint_doc_no = c.complaint_doc_no
                complaint_link = c.complaint_link
                
                if c.docket_id in doc_map:
                    doc = doc_map[c.docket_id]
                    complaint_doc_no = doc.doc_number or doc.doc_type
                    complaint_link = doc.document_url or doc.pdf_url
             
                if c.court_short_name and c.court_api_url:
                    court_display = _mdlink(c.court_short_name, c.court_api_url)
                else:
                    court_display = _esc(c.court)

                # =====================================================
                # FIX: Complaint PDF ë§í¬ í‘œì‹œ ê·œì¹™
                # - ë§í¬ ì¡´ì¬ ì‹œ: ğŸ“„ ì•„ì´ì½˜ ì¶œë ¥
                # - ë§í¬ ì—†ìœ¼ë©´: "-"
                # =====================================================
                if complaint_link:
                    complaint_link_display = _mdlink("ğŸ“„", complaint_link)
                else:
                    complaint_link_display = "-"

                # =====================================================
                # NEW: RECAP í…Œì´ë¸” ë¡œê·¸ ì¶œë ¥
                # =====================================================
                debug_log(f"RECAP row added: case={c.case_name}, docket={c.docket_number}, risk={score}")

                # =====================================================
                # NEW: Nature í•„ë“œ ê°•ì¡° ì²˜ë¦¬
                # - 820 Copyright â†’ ë¹¨ê°„ìƒ‰ í‘œì‹œ
                # =====================================================
                nature_display = _esc(c.nature_of_suit)
                if (c.nature_of_suit or "").strip() == "820 Copyright":
                    nature_display = 'âš ï¸**820 Copyright**'

                lines.append(
                    f"| {idx} | "
                    f"{_esc(c.status)} | "
                    f"{_mdlink(c.case_name, docket_url)} | "
                    f"{_mdlink(c.docket_number, docket_url)} | "
                    f"{nature_display} | "
                    f"{format_risk(score)} | "
                    f"{_short(extracted_causes, 120)} | "
                    f"{_short(extracted_ai_snippet, 120)} | "
                    f"{_esc(c.cause)} | "
                    f"{_esc(c.judge)} | "
                    f"{court_display} | "
                    f"{_esc(complaint_doc_no)} | "
                    f"{complaint_link_display} | "
                    f"{_esc(c.recent_updates)} |"
                )
        lines.append("")
    else:
        lines.append("ìƒˆë¡œìš´ ì†Œì‹ì´ 0ê±´ì…ë‹ˆë‹¤.\n")

    # RECAP ë²•ì› ë¬¸ì„œ (.pdf format)
    if cl_docs:
        lines.append("<details>")        
        lines.append("<summary><strong><span style=\"font-size:2.5em; font-weight:bold;\">ğŸ“„ Cases: ë²•ì› ë¬¸ì„œ ê¸°ë°˜ (Complaint/Petition ìš°ì„ )</span></strong></summary>\n")
        lines.append("| No. | ì œì¶œì¼â¬‡ï¸ | ì¼€ì´ìŠ¤ | ë¬¸ì„œìœ í˜• | ë²•ì› ë¬¸ì„œ |")
        lines.append(_md_sep(5))

        # ì œì¶œì¼ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_docs = sorted(
            cl_docs,
            key=lambda x: x.date_filed or "",
            reverse=True
        )

        for idx, d in enumerate(sorted_docs, start=1):
            link = d.document_url or d.pdf_url
            lines.append(
                f"| {idx} | "
                f"{_esc(d.date_filed)} | {_esc(d.case_name)} | "
                f"{_esc(d.doc_type)} | {_mdlink('ğŸ“„', link)} |"
            )
        lines.append("</details>\n")

    # ê¸°ì‚¬ ì£¼ì†Œ
    if lawsuits:
        lines.append("<details>")
        lines.append("<summary><strong><span style=\"font-size:2.5em; font-weight:bold;\">ğŸ“° News Website</span></strong></summary>\n")
        for s in lawsuits:
            lines.append(f"### {_esc(s.article_title or s.case_title)}")
            for u in s.article_urls:
                lines.append(f"- {u}")
        lines.append("</details>\n")

    # ìœ„í—˜ë„ ì²™ë„
    lines.append("<details>")
    lines.append("<summary><strong><span style=\"font-size:2.5em; font-weight:bold;\">ğŸ“˜ AI í•™ìŠµ ìœ„í—˜ë„ ì ìˆ˜(0~100) í‰ê°€ ì²™ë„</span></strong></summary>\n")
    lines.append("- AI ëª¨ë¸ í•™ìŠµê³¼ì˜ ì§ì ‘ì„± + ë²•ì  ë¦¬ìŠ¤í¬ ê°•ë„ë¥¼ ìˆ˜ì¹˜í™”í•œ ì§€í‘œì…ë‹ˆë‹¤.")
    lines.append("- 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ â†’ ê°„ì ‘/ì£¼ë³€ ì´ìŠˆ")
    lines.append("- 100ì— ê°€ê¹Œìš¸ìˆ˜ë¡ â†’ AI í•™ìŠµ í•µì‹¬ ë¦¬ìŠ¤í¬ ì‚¬ê±´\n")
    lines.append("")
    
    lines.append("### ğŸ“Š ë“±ê¸‰ ê¸°ì¤€")
    lines.append("-  0~ 39 ğŸŸ¢ : ê°„ì ‘ ì—°ê´€")
    lines.append("- 40~ 59 ğŸŸ¡ : í•™ìŠµ ìŸì  ì¡´ì¬")
    lines.append("- 60~ 79 âš ï¸ : ëª¨ë¸ í•™ìŠµ ì§ì ‘ ì–¸ê¸‰")
    lines.append("- 80~100 ğŸ”¥ : ë¬´ë‹¨ ìˆ˜ì§‘ + í•™ìŠµ + ìƒì—…ì  ì‚¬ìš© ê³ ìœ„í—˜")
    lines.append("")

    lines.append("### ğŸ§® ì ìˆ˜ ì‚°ì • ê¸°ì¤€")
    lines.append("| í•­ëª© | ì¡°ê±´ (ì£¼ìš” í‚¤ì›Œë“œ) | ì ìˆ˜ |")
    lines.append("|---|---|---|")
    lines.append("| ë¬´ë‹¨ ë°ì´í„° ìˆ˜ì§‘ ëª…ì‹œ | scrape, crawl, ingest, unauthorized ë“± | +30 |")
    lines.append("| ëª¨ë¸ í•™ìŠµ ì§ì ‘ ì–¸ê¸‰ | train, model, llm, generative ai, gpt ë“± | +30 |")
    lines.append("| ìƒì—…ì  ì‚¬ìš© | commercial, profit, monetiz, revenue ë“± | +15 |")
    lines.append("| ì €ì‘ê¶Œ ì†Œì†¡/ìŸì  | Nature=820, copyright, infringement, dmca ë“± | +15 |")
    lines.append("| ì§‘ë‹¨ì†Œì†¡ | class action, putative class ë“± | +10 |")
    lines.append("")

    lines.append("</details>\n")

    return "\n".join(lines) or ""
